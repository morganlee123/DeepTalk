{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "942134eb",
   "metadata": {
    "papermill": {
     "duration": 0.01644,
     "end_time": "2021-08-11T07:20:09.216841",
     "exception": false,
     "start_time": "2021-08-11T07:20:09.200401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SER LSTM Training Script\n",
    "\n",
    "## Morgan Sandler (sandle20@msu.edu) - Michigan State University"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c2fc13",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- train on the 256 dim embeddings (stored in var=embeddings)\n",
    "- Correct the shape of the embeddings to train to (SIZE OF TRAIN, SIZE OF SPLIT SEGMENTS, 256)\n",
    "- extract 3 second long overlapping windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6461ba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:20:09.259814Z",
     "iopub.status.busy": "2021-08-11T07:20:09.259270Z",
     "iopub.status.idle": "2021-08-11T07:20:16.090758Z",
     "shell.execute_reply": "2021-08-11T07:20:16.090153Z",
     "shell.execute_reply.started": "2021-06-21T09:09:34.937775Z"
    },
    "papermill": {
     "duration": 6.858444,
     "end_time": "2021-08-11T07:20:16.090899",
     "exception": false,
     "start_time": "2021-08-11T07:20:09.232455",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1f49e232a01c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#from tensorflow.keras.callbacks import ReduceLROnPlateau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/keras/api/_v2/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_source_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/keras/engine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# note: `Node` is an internal class,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# it isn't meant to be used by Keras users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# from ALL_OBJECTS. We make no guarantees as to whether these objects will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# using their correct version.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36mpopulate_deserializable_objects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mv2_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mbase_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     generic_utils.populate_dict_with_module_objects(\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mv2_objs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0minitializers_v2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[1], device_type='GPU')\n",
    "tf.config.experimental.set_memory_growth(device=gpus[1], enable=True)\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed92b7",
   "metadata": {
    "papermill": {
     "duration": 0.015176,
     "end_time": "2021-08-11T07:20:16.122259",
     "exception": false,
     "start_time": "2021-08-11T07:20:16.107083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load CREMA-D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be83bffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:20:16.157172Z",
     "iopub.status.busy": "2021-08-11T07:20:16.156550Z",
     "iopub.status.idle": "2021-08-11T07:20:16.160488Z",
     "shell.execute_reply": "2021-08-11T07:20:16.160064Z",
     "shell.execute_reply.started": "2021-06-21T09:35:38.093838Z"
    },
    "papermill": {
     "duration": 0.022965,
     "end_time": "2021-08-11T07:20:16.160600",
     "exception": false,
     "start_time": "2021-08-11T07:20:16.137635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Crema = \"/research/iprobe-sandle20/sandle20/CREMA-D/AudioWAV/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11747ead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:20:16.198612Z",
     "iopub.status.busy": "2021-08-11T07:20:16.198067Z",
     "iopub.status.idle": "2021-08-11T07:20:16.491849Z",
     "shell.execute_reply": "2021-08-11T07:20:16.492267Z",
     "shell.execute_reply.started": "2021-06-21T09:36:24.417703Z"
    },
    "papermill": {
     "duration": 0.316723,
     "end_time": "2021-08-11T07:20:16.492410",
     "exception": false,
     "start_time": "2021-08-11T07:20:16.175687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Crema' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b64b1a4da253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrema_directory_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCrema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_emotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_subject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Crema' is not defined"
     ]
    }
   ],
   "source": [
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "file_subject = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    \n",
    "    # part[0] refers to the subject number. start new list for this information\n",
    "    file_subject.append(int(part[0]))\n",
    "    \n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "\n",
    "# dataframe for the subject numbers\n",
    "subjects_df = pd.DataFrame(file_subject, columns=['Subject'])\n",
    "\n",
    "Crema_df = pd.concat([emotion_df, path_df, subjects_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8615949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:20:16.542514Z",
     "iopub.status.busy": "2021-08-11T07:20:16.541842Z",
     "iopub.status.idle": "2021-08-11T07:20:16.682448Z",
     "shell.execute_reply": "2021-08-11T07:20:16.682857Z",
     "shell.execute_reply.started": "2021-06-21T09:36:25.200452Z"
    },
    "papermill": {
     "duration": 0.174507,
     "end_time": "2021-08-11T07:20:16.683000",
     "exception": false,
     "start_time": "2021-08-11T07:20:16.508493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Count of Emotions', size=16)\n",
    "sns.countplot(Crema_df.Emotions)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4cfdc8",
   "metadata": {
    "papermill": {
     "duration": 0.015694,
     "end_time": "2021-08-11T07:20:16.715045",
     "exception": false,
     "start_time": "2021-08-11T07:20:16.699351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualization of signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7a26c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:20:16.753470Z",
     "iopub.status.busy": "2021-08-11T07:20:16.752779Z",
     "iopub.status.idle": "2021-08-11T07:20:16.755452Z",
     "shell.execute_reply": "2021-08-11T07:20:16.755037Z",
     "shell.execute_reply.started": "2021-06-21T09:36:27.274257Z"
    },
    "papermill": {
     "duration": 0.024397,
     "end_time": "2021-08-11T07:20:16.755560",
     "exception": false,
     "start_time": "2021-08-11T07:20:16.731163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr, e):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title('Waveplot for {} emotion'.format(e), size=15)\n",
    "    librosa.display.waveplot(data, sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def create_spectrogram(data, sr, e):\n",
    "    X = librosa.stft(data)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title('Spectrogram for {} emotion'.format(e), size=15)\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e8c68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:20:16.795053Z",
     "iopub.status.busy": "2021-08-11T07:20:16.794382Z",
     "iopub.status.idle": "2021-08-11T07:20:17.764833Z",
     "shell.execute_reply": "2021-08-11T07:20:17.765260Z",
     "shell.execute_reply.started": "2021-06-21T09:36:28.243518Z"
    },
    "papermill": {
     "duration": 0.993849,
     "end_time": "2021-08-11T07:20:17.765405",
     "exception": false,
     "start_time": "2021-08-11T07:20:16.771556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion='sad'\n",
    "path = np.array(Crema_df.Path[Crema_df.Emotions==emotion])[1]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "create_waveplot(data, sampling_rate, emotion)\n",
    "create_spectrogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22888169",
   "metadata": {
    "papermill": {
     "duration": 0.021308,
     "end_time": "2021-08-11T07:20:17.808753",
     "exception": false,
     "start_time": "2021-08-11T07:20:17.787445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature extraction (DeepTalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e7b30c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:20:17.857686Z",
     "iopub.status.busy": "2021-08-11T07:20:17.856777Z",
     "iopub.status.idle": "2021-08-11T07:20:17.867146Z",
     "shell.execute_reply": "2021-08-11T07:20:17.867577Z",
     "shell.execute_reply.started": "2021-06-21T09:35:40.689519Z"
    },
    "papermill": {
     "duration": 0.036854,
     "end_time": "2021-08-11T07:20:17.867716",
     "exception": false,
     "start_time": "2021-08-11T07:20:17.830862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Crema_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5372901cec1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'disgust'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'happy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sad'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'neutral'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'angry'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mCrema_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Emotions'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Crema_df' is not defined"
     ]
    }
   ],
   "source": [
    "labels = {'disgust':0,'happy':1,'sad':2,'neutral':3,'fear':4,'angry':5}\n",
    "Crema_df.replace({'Emotions':labels},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae61582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:20:17.917849Z",
     "iopub.status.busy": "2021-08-11T07:20:17.917232Z",
     "iopub.status.idle": "2021-08-11T07:34:58.225463Z",
     "shell.execute_reply": "2021-08-11T07:34:58.226645Z",
     "shell.execute_reply.started": "2021-06-21T08:44:45.743254Z"
    },
    "papermill": {
     "duration": 880.337503,
     "end_time": "2021-08-11T07:34:58.226915",
     "exception": false,
     "start_time": "2021-08-11T07:20:17.889412",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /research/iprobe-sandle20/sandle20/SpeechEmotionRecognitionExperiments/DeepTalk/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n",
      "TURNING OFF WARNINGS in tools/sigproc.py!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.9918367346938775\n",
      "43920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:06<14:52,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 100\n",
      "0\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.110204081632653\n",
      "24480\n",
      "Total embeddings returned: 12\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7850340136054421\n",
      "39360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  2%|▏         | 3/200 [00:07<10:57,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 79\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7850340136054421\n",
      "39360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  2%|▏         | 4/200 [00:07<08:14,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 79\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "3.0258503401360546\n",
      "66720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  2%|▎         | 5/200 [00:09<07:06,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 204\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.251700680272109\n",
      "27600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  3%|▎         | 6/200 [00:09<05:13,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 26\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.5251700680272107\n",
      "55680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  4%|▎         | 7/200 [00:10<04:42,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 154\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5564625850340137\n",
      "34320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  4%|▍         | 8/200 [00:11<03:43,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 57\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2299319727891156\n",
      "27120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  4%|▍         | 9/200 [00:11<02:51,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 24\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4149659863945578\n",
      "31200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  5%|▌         | 10/200 [00:11<02:21,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 42\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.2095238095238097\n",
      "48720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  6%|▌         | 11/200 [00:12<02:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 122\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.1006802721088436\n",
      "46320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  6%|▌         | 12/200 [00:13<02:30,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 111\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6435374149659865\n",
      "36240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  6%|▋         | 13/200 [00:13<02:15,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 65\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4040816326530612\n",
      "30960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  7%|▋         | 14/200 [00:14<01:55,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 41\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5238095238095237\n",
      "33600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  8%|▊         | 15/200 [00:14<01:45,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 53\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7850340136054421\n",
      "39360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  8%|▊         | 16/200 [00:15<01:47,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 79\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.3931972789115645\n",
      "30720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  8%|▊         | 17/200 [00:15<01:35,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 40\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.327891156462585\n",
      "29280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  9%|▉         | 18/200 [00:16<01:25,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 34\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7850340136054421\n",
      "39360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|▉         | 19/200 [00:16<01:33,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 79\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.491156462585034\n",
      "32880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|█         | 20/200 [00:17<01:28,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 50\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5346938775510204\n",
      "33840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|█         | 21/200 [00:17<01:26,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 54\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.980952380952381\n",
      "43680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 11%|█         | 22/200 [00:18<01:39,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 99\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6435374149659865\n",
      "36240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 12%|█▏        | 23/200 [00:18<01:37,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 65\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6653061224489796\n",
      "36720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 12%|█▏        | 24/200 [00:19<01:37,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 67\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.895238095238095\n",
      "63840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 12%|█▎        | 25/200 [00:20<02:16,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 191\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.492517006802721\n",
      "54960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 13%|█▎        | 26/200 [00:21<02:30,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 150\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4802721088435373\n",
      "32640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 14%|█▎        | 27/200 [00:22<02:07,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 49\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.8068027210884354\n",
      "39840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 14%|█▍        | 28/200 [00:22<02:02,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 82\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.382312925170068\n",
      "30480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 14%|█▍        | 29/200 [00:23<01:44,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 39\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.3496598639455781\n",
      "29760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|█▌        | 30/200 [00:23<01:29,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 36\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.3387755102040817\n",
      "29520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [00:24<01:02,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 35\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.0231292517006803\n",
      "22560\n",
      "Total embeddings returned: 3\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.3496598639455781\n",
      "29760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 16%|█▋        | 33/200 [00:24<01:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 36\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6435374149659865\n",
      "36240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 17%|█▋        | 34/200 [00:25<01:08,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 65\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6435374149659865\n",
      "36240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 18%|█▊        | 35/200 [00:25<01:13,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 65\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.545578231292517\n",
      "34080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 18%|█▊        | 36/200 [00:26<01:14,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 55\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.0027210884353743\n",
      "44160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 18%|█▊        | 37/200 [00:26<01:29,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 101\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.1863945578231292\n",
      "26160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 19%|█▉        | 38/200 [00:27<01:14,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 19\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.273469387755102\n",
      "28080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|█▉        | 39/200 [00:27<01:06,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 28\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.3061224489795917\n",
      "28800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [00:27<00:49,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 31\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.9904761904761905\n",
      "21840\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.0462585034013605\n",
      "45120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 21%|██        | 42/200 [00:28<01:11,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 106\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.708843537414966\n",
      "37680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 22%|██▏       | 43/200 [00:29<01:16,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 72\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7306122448979593\n",
      "38160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 22%|██▏       | 44/200 [00:29<01:20,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 74\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.763265306122449\n",
      "38880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 22%|██▎       | 45/200 [00:30<01:23,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 77\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.491156462585034\n",
      "32880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 23%|██▎       | 46/200 [00:30<01:18,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 50\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7850340136054421\n",
      "39360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 24%|██▎       | 47/200 [00:31<01:22,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 79\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7414965986394557\n",
      "38400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 24%|██▍       | 48/200 [00:32<01:25,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 75\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.024489795918367\n",
      "44640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 24%|██▍       | 49/200 [00:32<01:34,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 103\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7306122448979593\n",
      "38160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|██▌       | 50/200 [00:33<01:31,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 74\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6217687074829932\n",
      "35760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 26%|██▌       | 51/200 [00:33<01:28,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 63\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5238095238095237\n",
      "33600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 26%|██▌       | 52/200 [00:34<01:21,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 53\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6435374149659865\n",
      "36240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 26%|██▋       | 53/200 [00:34<01:20,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 65\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6217687074829932\n",
      "35760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 27%|██▋       | 54/200 [00:35<01:18,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 63\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2299319727891156\n",
      "27120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 28%|██▊       | 55/200 [00:35<01:06,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 24\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7741496598639457\n",
      "39120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 28%|██▊       | 56/200 [00:36<01:12,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 78\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4258503401360545\n",
      "31440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 28%|██▊       | 57/200 [00:36<01:09,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 43\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5346938775510204\n",
      "33840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 29%|██▉       | 58/200 [00:37<01:09,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 54\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5673469387755101\n",
      "34560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|██▉       | 59/200 [00:37<01:10,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 58\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.491156462585034\n",
      "32880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|███       | 60/200 [00:38<01:07,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 50\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.763265306122449\n",
      "38880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|███       | 61/200 [00:38<01:12,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 77\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.3496598639455781\n",
      "29760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 31%|███       | 62/200 [00:39<01:05,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 36\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.708843537414966\n",
      "37680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 32%|███▏      | 63/200 [00:39<01:10,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 72\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6435374149659865\n",
      "36240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 32%|███▏      | 64/200 [00:40<01:11,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 65\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.926530612244898\n",
      "42480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 32%|███▎      | 65/200 [00:41<01:20,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 94\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.763265306122449\n",
      "38880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [00:41<01:05,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 77\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.0775510204081633\n",
      "23760\n",
      "Total embeddings returned: 9\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6108843537414965\n",
      "35520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 34%|███▍      | 68/200 [00:42<01:06,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 62\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4258503401360545\n",
      "31440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 34%|███▍      | 69/200 [00:42<01:02,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 43\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6979591836734693\n",
      "37440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 35%|███▌      | 70/200 [00:43<01:06,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 71\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4258503401360545\n",
      "31440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 36%|███▌      | 71/200 [00:43<01:02,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 43\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.2965986394557825\n",
      "50640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/200 [00:45<01:01,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 131\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.0013605442176872\n",
      "22080\n",
      "Total embeddings returned: 1\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5020408163265306\n",
      "33120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75/200 [00:45<00:46,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 51\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.9142857142857143\n",
      "20160\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.0789115646258503\n",
      "45840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 38%|███▊      | 76/200 [00:46<01:03,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 109\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7523809523809524\n",
      "38640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 38%|███▊      | 77/200 [00:47<01:07,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 76\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.980952380952381\n",
      "43680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79/200 [00:48<00:57,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 99\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.8163265306122449\n",
      "18000\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.8612244897959183\n",
      "41040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|████      | 80/200 [00:48<01:04,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 87\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.11156462585034\n",
      "46560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|████      | 81/200 [00:49<01:15,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 112\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.9591836734693877\n",
      "43200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 41%|████      | 82/200 [00:50<01:19,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 97\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.3605442176870748\n",
      "30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 84/200 [00:50<00:51,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 37\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.9142857142857143\n",
      "20160\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7850340136054421\n",
      "39360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 42%|████▎     | 85/200 [00:51<00:57,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 79\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.926530612244898\n",
      "42480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 43%|████▎     | 86/200 [00:52<01:10,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 94\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2625850340136053\n",
      "27840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 44%|████▎     | 87/200 [00:52<00:59,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 27\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.5251700680272107\n",
      "55680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 44%|████▍     | 88/200 [00:53<01:19,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 154\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.122448979591837\n",
      "46800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 44%|████▍     | 89/200 [00:54<01:24,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 113\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7850340136054421\n",
      "39360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 45%|████▌     | 90/200 [00:55<01:19,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 79\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.1210884353741497\n",
      "24720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 46%|████▌     | 91/200 [00:55<01:02,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 13\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.469387755102041\n",
      "32400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 46%|████▌     | 92/200 [00:56<00:58,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 48\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6761904761904762\n",
      "36960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 46%|████▋     | 93/200 [00:56<00:58,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 69\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6870748299319729\n",
      "37200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 47%|████▋     | 94/200 [00:57<00:59,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 70\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.459863945578231\n",
      "54240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 48%|████▊     | 95/200 [00:58<01:15,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 147\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.1755102040816328\n",
      "25920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 48%|████▊     | 96/200 [00:58<01:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 18\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7523809523809524\n",
      "38640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 48%|████▊     | 97/200 [00:59<01:01,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 76\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.8938775510204082\n",
      "41760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 49%|████▉     | 98/200 [00:59<01:04,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 90\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6870748299319729\n",
      "37200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|████▉     | 99/200 [01:00<01:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 70\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.3401360544217686\n",
      "51600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████     | 100/200 [01:01<01:13,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 135\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.3714285714285714\n",
      "30240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████     | 101/200 [01:01<01:02,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 38\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.327891156462585\n",
      "29280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 51%|█████     | 102/200 [01:02<00:53,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 34\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6761904761904762\n",
      "36960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 52%|█████▏    | 103/200 [01:02<00:53,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 69\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.3170068027210884\n",
      "29040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 52%|█████▏    | 104/200 [01:03<00:47,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 33\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5891156462585034\n",
      "35040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 52%|█████▎    | 105/200 [01:03<00:47,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 60\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.9047619047619047\n",
      "42000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 53%|█████▎    | 106/200 [01:04<00:53,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 91\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.9047619047619047\n",
      "42000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 54%|█████▎    | 107/200 [01:05<00:57,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 91\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4040816326530612\n",
      "30960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 54%|█████▍    | 108/200 [01:05<00:51,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 41\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2952380952380953\n",
      "28560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████▍    | 109/200 [01:05<00:44,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 30\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.763265306122449\n",
      "38880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████▌    | 110/200 [01:06<00:47,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 77\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.545578231292517\n",
      "34080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 56%|█████▌    | 111/200 [01:06<00:46,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 55\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.9156462585034013\n",
      "42240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 56%|█████▌    | 112/200 [01:07<00:51,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 93\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4258503401360545\n",
      "31440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 56%|█████▋    | 113/200 [01:08<00:46,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 43\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6435374149659865\n",
      "36240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 57%|█████▋    | 114/200 [01:08<00:46,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 65\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.9047619047619047\n",
      "42000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 116/200 [01:09<00:37,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 91\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.8598639455782313\n",
      "18960\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.436734693877551\n",
      "31680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 58%|█████▊    | 117/200 [01:09<00:38,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 45\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2843537414965986\n",
      "28320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 119/200 [01:10<00:26,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 29\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.8707482993197279\n",
      "19200\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.0027210884353743\n",
      "44160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|██████    | 120/200 [01:11<00:37,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 101\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.2312925170068025\n",
      "49200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|██████    | 121/200 [01:12<00:48,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 124\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.8068027210884354\n",
      "39840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 61%|██████    | 122/200 [01:12<00:49,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 82\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5782312925170068\n",
      "34800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 62%|██████▏   | 123/200 [01:13<00:46,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 59\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7959183673469388\n",
      "39600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 125/200 [01:14<00:35,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 81\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.9904761904761905\n",
      "21840\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.3931972789115645\n",
      "30720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 63%|██████▎   | 126/200 [01:14<00:33,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 40\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6653061224489796\n",
      "36720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 64%|██████▎   | 127/200 [01:15<00:35,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 67\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.469387755102041\n",
      "32400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 64%|██████▍   | 128/200 [01:15<00:33,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 48\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.110204081632653\n",
      "24480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 64%|██████▍   | 129/200 [01:15<00:27,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 12\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.0027210884353743\n",
      "44160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 65%|██████▌   | 130/200 [01:16<00:35,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 101\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6653061224489796\n",
      "36720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 66%|██████▌   | 131/200 [01:17<00:37,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 67\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.926530612244898\n",
      "42480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 66%|██████▌   | 132/200 [01:17<00:41,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 94\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2081632653061225\n",
      "26640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 134/200 [01:18<00:25,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 22\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.7292517006802721\n",
      "16080\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6435374149659865\n",
      "36240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 68%|██████▊   | 135/200 [01:18<00:28,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 65\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5564625850340137\n",
      "34320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 68%|██████▊   | 136/200 [01:19<00:29,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 57\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6435374149659865\n",
      "36240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 68%|██████▊   | 137/200 [01:19<00:30,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 65\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.763265306122449\n",
      "38880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 69%|██████▉   | 138/200 [01:20<00:33,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 77\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4476190476190476\n",
      "31920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|██████▉   | 139/200 [01:21<00:30,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 46\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5891156462585034\n",
      "35040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|███████   | 140/200 [01:21<00:30,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 60\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.220408163265306\n",
      "48960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|███████   | 141/200 [01:22<00:37,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 123\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.763265306122449\n",
      "38880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 71%|███████   | 142/200 [01:23<00:36,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 77\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5782312925170068\n",
      "34800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 72%|███████▏  | 143/200 [01:23<00:34,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 59\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7414965986394557\n",
      "38400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 72%|███████▏  | 144/200 [01:24<00:34,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 75\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.1755102040816328\n",
      "25920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 72%|███████▎  | 145/200 [01:24<00:27,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 18\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.8829931972789116\n",
      "41520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 73%|███████▎  | 146/200 [01:25<00:30,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 89\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.382312925170068\n",
      "30480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 74%|███████▎  | 147/200 [01:25<00:27,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 39\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.17687074829932\n",
      "48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 74%|███████▍  | 148/200 [01:26<00:32,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 119\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.545578231292517\n",
      "34080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 74%|███████▍  | 149/200 [01:27<00:29,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 55\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2625850340136053\n",
      "27840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 75%|███████▌  | 150/200 [01:27<00:25,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 27\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.122448979591837\n",
      "46800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 76%|███████▌  | 151/200 [01:28<00:30,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 113\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.122448979591837\n",
      "46800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 76%|███████▌  | 152/200 [01:29<00:32,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 113\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.273469387755102\n",
      "28080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 76%|███████▋  | 153/200 [01:29<00:27,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 28\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.6340136054421768\n",
      "58080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 77%|███████▋  | 154/200 [01:30<00:35,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 165\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.654421768707483\n",
      "36480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 78%|███████▊  | 155/200 [01:31<00:31,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 66\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.8938775510204082\n",
      "41760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 78%|███████▊  | 156/200 [01:31<00:31,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 90\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2408163265306122\n",
      "27360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 78%|███████▊  | 157/200 [01:32<00:25,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 25\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6653061224489796\n",
      "36720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 79%|███████▉  | 158/200 [01:32<00:24,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 67\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.8081632653061224\n",
      "61920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|███████▉  | 159/200 [01:34<00:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 182\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.0027210884353743\n",
      "44160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|████████  | 160/200 [01:34<00:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 101\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6653061224489796\n",
      "36720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|████████  | 161/200 [01:35<00:28,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 67\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.927891156462585\n",
      "64560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 81%|████████  | 162/200 [01:36<00:35,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 194\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4476190476190476\n",
      "31920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 164/200 [01:37<00:21,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 46\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.9142857142857143\n",
      "20160\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.3061224489795917\n",
      "28800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 82%|████████▎ | 165/200 [01:37<00:18,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 31\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2081632653061225\n",
      "26640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 167/200 [01:38<00:11,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 22\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.9795918367346939\n",
      "21600\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2299319727891156\n",
      "27120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 84%|████████▍ | 168/200 [01:38<00:10,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 24\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.9591836734693877\n",
      "43200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 84%|████████▍ | 169/200 [01:39<00:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 97\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.7414965986394557\n",
      "38400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 171/200 [01:40<00:13,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 75\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.8707482993197279\n",
      "19200\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.068027210884354\n",
      "45600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 86%|████████▌ | 172/200 [01:41<00:17,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 108\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.0993197278911564\n",
      "24240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 86%|████████▋ | 173/200 [01:41<00:13,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 11\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.327891156462585\n",
      "29280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 175/200 [01:42<00:09,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 34\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "0.9687074829931973\n",
      "21360\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.382312925170068\n",
      "30480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 88%|████████▊ | 176/200 [01:42<00:09,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 39\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6435374149659865\n",
      "36240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 88%|████████▊ | 177/200 [01:43<00:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 65\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.273469387755102\n",
      "28080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 89%|████████▉ | 178/200 [01:43<00:09,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 28\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.110204081632653\n",
      "24480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|████████▉ | 179/200 [01:43<00:07,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 12\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.926530612244898\n",
      "42480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|█████████ | 180/200 [01:44<00:10,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 94\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4040816326530612\n",
      "30960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|█████████ | 181/200 [01:45<00:09,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 41\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.742857142857143\n",
      "60480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 91%|█████████ | 182/200 [01:46<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 175\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.817687074829932\n",
      "40080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 92%|█████████▏| 183/200 [01:47<00:13,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 83\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6435374149659865\n",
      "36240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 92%|█████████▏| 184/200 [01:48<00:12,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 65\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.8938775510204082\n",
      "41760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 92%|█████████▎| 185/200 [01:48<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 90\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.0462585034013605\n",
      "45120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 93%|█████████▎| 186/200 [01:49<00:11,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 106\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.4476190476190476\n",
      "31920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 94%|█████████▎| 187/200 [01:50<00:09,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 46\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.1442176870748297\n",
      "47280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 94%|█████████▍| 188/200 [01:51<00:09,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 115\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2299319727891156\n",
      "27120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 94%|█████████▍| 189/200 [01:51<00:07,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 24\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.708843537414966\n",
      "37680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 95%|█████████▌| 190/200 [01:52<00:06,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 72\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6870748299319729\n",
      "37200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 96%|█████████▌| 191/200 [01:53<00:06,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 70\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "2.2421768707482994\n",
      "49440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 96%|█████████▌| 192/200 [01:54<00:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 125\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.763265306122449\n",
      "38880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 96%|█████████▋| 193/200 [01:54<00:05,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 77\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5238095238095237\n",
      "33600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 97%|█████████▋| 194/200 [01:55<00:04,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 53\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5346938775510204\n",
      "33840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 98%|█████████▊| 195/200 [01:56<00:03,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 54\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.0993197278911564\n",
      "24240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 98%|█████████▊| 196/200 [01:56<00:02,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 11\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.654421768707483\n",
      "36480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 98%|█████████▊| 197/200 [01:56<00:01,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 66\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.5782312925170068\n",
      "34800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 99%|█████████▉| 198/200 [01:57<00:01,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 59\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.2081632653061225\n",
      "26640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "100%|█████████▉| 199/200 [01:57<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 22\n",
      "Loaded encoder \"model_GST.pt\" trained to step 630501\n",
      "Found synthesizer \"model_GST\" trained to step 558000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at trained_models/Generic/Vocoder/model_GST/model_GST.pt\n",
      "---------------------------------------------------------------\n",
      "Stage 1/3: Encoder\n",
      "---------------------------------------------------------------\n",
      "1.6\n",
      "35280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:58<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings returned: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import demo_functions as dt_func\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "data = {\n",
    "        \"subject\": [],\n",
    "        \"labels\": [],\n",
    "        \"dt\": []\n",
    "    }\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(200)):#7442)):\n",
    "    data['subject'].append(Crema_df.iloc[i,2])\n",
    "    data['labels'].append(Crema_df.iloc[i,0])\n",
    "    #signal, sample_rate = librosa.load(Crema_df.iloc[i,1], sr=SAMPLE_RATE)\n",
    "    \n",
    "    # Compute DeepTalk embeddings\n",
    "    try:\n",
    "        embeddings = dt_func.run_DeepTalk_demo(ref_audio_path=Crema_df.iloc[i, 1])\n",
    "    except:\n",
    "        continue\n",
    "    #if embeddings. == None:\n",
    "    #    continue\n",
    "    #print(embeddings)    \n",
    "    #embeddings = embeddings.T\n",
    "    data[\"dt\"].append(np.asarray(embeddings))\n",
    "    if i%500==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53b711f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:34:58.392719Z",
     "iopub.status.busy": "2021-08-11T07:34:58.391878Z",
     "iopub.status.idle": "2021-08-11T07:34:58.394441Z",
     "shell.execute_reply": "2021-08-11T07:34:58.394011Z",
     "shell.execute_reply.started": "2021-06-21T09:12:20.176342Z"
    },
    "papermill": {
     "duration": 0.034542,
     "end_time": "2021-08-11T07:34:58.394563",
     "exception": false,
     "start_time": "2021-08-11T07:34:58.360021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(data['dt'])\n",
    "X_sub = np.asarray(data['subject'])\n",
    "y = np.asarray(data[\"labels\"])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "422dd08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 204, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, dtype='float32')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11a1a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject disjointness between train/validation/test\n",
    "\n",
    "possible_subjects = list(range(1001, 1092))\n",
    "\n",
    "TRAIN_SIZE = 0.7 # Training sample of the data\n",
    "TEST_SIZE = 0.1 # Used for final testing of performance for extra rigor\n",
    "VALIDATION_SIZE = 0.2 # Used in the training of the model for validation data\n",
    "\n",
    "# Determine which subjects belong to which set\n",
    "X_train_subs, X_test_subs = train_test_split(possible_subjects, test_size=TEST_SIZE)\n",
    "X_train_subs, X_val_subs = train_test_split(X_train_subs, test_size=VALIDATION_SIZE)\n",
    "\n",
    "# There are now 3 sets of subjects X_train_subs | X_test_subs | X_val_subs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d99e9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_validation = []\n",
    "y_validation = []\n",
    "\n",
    "for i in range(X.shape[0]):#7371):\n",
    "    if data['subject'][i] in X_train_subs:\n",
    "        X_train.append(X[i])\n",
    "        y_train.append(y[i])\n",
    "    elif data['subject'][i] in X_test_subs:\n",
    "        X_test.append(X[i])\n",
    "        y_test.append(y[i])\n",
    "    elif data['subject'][i] in X_val_subs:\n",
    "        X_validation.append(X[i])\n",
    "        y_validation.append(y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce17da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_validation = np.asarray(X_validation)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "y_validation = np.asarray(y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cea568e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:34:58.706994Z",
     "iopub.status.busy": "2021-08-11T07:34:58.705746Z",
     "iopub.status.idle": "2021-08-11T07:34:58.709336Z",
     "shell.execute_reply": "2021-08-11T07:34:58.709935Z",
     "shell.execute_reply.started": "2021-06-21T09:12:53.639297Z"
    },
    "papermill": {
     "duration": 0.035993,
     "end_time": "2021-08-11T07:34:58.710099",
     "exception": false,
     "start_time": "2021-08-11T07:34:58.674106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 204, 256) (133,) (38, 204, 256) (38,) (17, 204, 256) (17,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_validation.shape,y_validation.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6ef6c",
   "metadata": {
    "papermill": {
     "duration": 0.027647,
     "end_time": "2021-08-11T07:34:58.765879",
     "exception": false,
     "start_time": "2021-08-11T07:34:58.738232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16f39edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:34:58.826763Z",
     "iopub.status.busy": "2021-08-11T07:34:58.825224Z",
     "iopub.status.idle": "2021-08-11T07:34:58.827484Z",
     "shell.execute_reply": "2021-08-11T07:34:58.827889Z",
     "shell.execute_reply.started": "2021-06-21T09:31:00.855572Z"
    },
    "papermill": {
     "duration": 0.034818,
     "end_time": "2021-08-11T07:34:58.828020",
     "exception": false,
     "start_time": "2021-08-11T07:34:58.793202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Layer of LSTM\n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(LSTM(64))\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    # Dropout layer to combat overfitting\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Softmax function to convert to probabilities for six emotional classes\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebeba9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pywrap_tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fb7827546373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMACNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/research/iprobe-sandle20/sandle20/SpeechEmotionRecognitionExperiments/DeepTalk/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor2tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marea_attention\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0marea_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pywrap_tensorflow'"
     ]
    }
   ],
   "source": [
    "from model import MACNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54312f86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:34:58.885456Z",
     "iopub.status.busy": "2021-08-11T07:34:58.884920Z",
     "iopub.status.idle": "2021-08-11T07:35:01.517183Z",
     "shell.execute_reply": "2021-08-11T07:35:01.517751Z",
     "shell.execute_reply.started": "2021-06-21T09:31:02.996423Z"
    },
    "papermill": {
     "duration": 2.663376,
     "end_time": "2021-08-11T07:35:01.517946",
     "exception": false,
     "start_time": "2021-08-11T07:34:58.854570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 128)         197120    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 251,078\n",
      "Trainable params: 251,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create network\n",
    "input_shape = (None, 256)\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# compile model\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimiser,\n",
    "                  loss='sparse_categorical_crossentropy', # TODO: Try another loss function???\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2dce73",
   "metadata": {
    "papermill": {
     "duration": 0.02593,
     "end_time": "2021-08-11T07:35:01.570540",
     "exception": false,
     "start_time": "2021-08-11T07:35:01.544610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46a6a06a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:35:01.627260Z",
     "iopub.status.busy": "2021-08-11T07:35:01.626586Z",
     "iopub.status.idle": "2021-08-11T07:37:01.869990Z",
     "shell.execute_reply": "2021-08-11T07:37:01.869339Z",
     "shell.execute_reply.started": "2021-06-21T09:31:04.66912Z"
    },
    "papermill": {
     "duration": 120.27337,
     "end_time": "2021-08-11T07:37:01.870175",
     "exception": false,
     "start_time": "2021-08-11T07:35:01.596805",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 133 samples, validate on 38 samples\n",
      "WARNING:tensorflow:From /research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "133/133 [==============================] - 10s 79ms/sample - loss: 1.7998 - acc: 0.1053 - val_loss: 1.7968 - val_acc: 0.1842\n",
      "Epoch 2/100\n",
      "133/133 [==============================] - 8s 63ms/sample - loss: 1.7861 - acc: 0.1880 - val_loss: 1.7978 - val_acc: 0.0789\n",
      "Epoch 3/100\n",
      "133/133 [==============================] - 9s 66ms/sample - loss: 1.7548 - acc: 0.2932 - val_loss: 1.7981 - val_acc: 0.1579\n",
      "Epoch 4/100\n",
      "133/133 [==============================] - 9s 66ms/sample - loss: 1.7182 - acc: 0.2331 - val_loss: 1.8412 - val_acc: 0.1316\n",
      "Epoch 5/100\n",
      "133/133 [==============================] - 8s 64ms/sample - loss: 1.6533 - acc: 0.3308 - val_loss: 1.8560 - val_acc: 0.1579\n",
      "Epoch 6/100\n",
      "133/133 [==============================] - 8s 63ms/sample - loss: 1.6376 - acc: 0.3383 - val_loss: 1.9665 - val_acc: 0.2368\n",
      "Epoch 7/100\n",
      "133/133 [==============================] - 9s 64ms/sample - loss: 1.5695 - acc: 0.3083 - val_loss: 1.9945 - val_acc: 0.1053\n",
      "Epoch 8/100\n",
      "133/133 [==============================] - 9s 64ms/sample - loss: 1.5756 - acc: 0.2932 - val_loss: 1.9947 - val_acc: 0.2368\n",
      "Epoch 9/100\n",
      "133/133 [==============================] - 9s 65ms/sample - loss: 1.4996 - acc: 0.4060 - val_loss: 2.1946 - val_acc: 0.0789\n",
      "Epoch 10/100\n",
      "133/133 [==============================] - 9s 65ms/sample - loss: 1.4732 - acc: 0.3985 - val_loss: 2.0244 - val_acc: 0.2368\n",
      "Epoch 11/100\n",
      "133/133 [==============================] - 9s 64ms/sample - loss: 1.3608 - acc: 0.4586 - val_loss: 2.1385 - val_acc: 0.1053\n",
      "Epoch 12/100\n",
      "133/133 [==============================] - 9s 64ms/sample - loss: 1.3835 - acc: 0.4361 - val_loss: 2.2939 - val_acc: 0.2105\n",
      "Epoch 13/100\n",
      "133/133 [==============================] - 8s 62ms/sample - loss: 1.4502 - acc: 0.4436 - val_loss: 2.1680 - val_acc: 0.1579\n",
      "Epoch 14/100\n",
      "133/133 [==============================] - 8s 62ms/sample - loss: 1.2878 - acc: 0.5188 - val_loss: 2.3043 - val_acc: 0.1579\n",
      "Epoch 15/100\n",
      "133/133 [==============================] - 8s 64ms/sample - loss: 1.1357 - acc: 0.5338 - val_loss: 2.6988 - val_acc: 0.1579\n",
      "Epoch 16/100\n",
      "133/133 [==============================] - 9s 66ms/sample - loss: 1.2903 - acc: 0.5038 - val_loss: 2.6714 - val_acc: 0.1579\n",
      "Epoch 17/100\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.2434 - acc: 0.5385"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7432e9c073ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/research/iprobe-sandle20/miniconda3/envs/deeptalk/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, min_delta=0.01)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=10, epochs=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ac1b1",
   "metadata": {
    "papermill": {
     "duration": 0.505467,
     "end_time": "2021-08-11T07:37:02.901199",
     "exception": false,
     "start_time": "2021-08-11T07:37:02.395732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d8de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "#model = keras.models.load_model('./Speech-Emotion-Recognition-Model-.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6121dfc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:37:04.182042Z",
     "iopub.status.busy": "2021-08-11T07:37:04.181089Z",
     "iopub.status.idle": "2021-08-11T07:37:04.422281Z",
     "shell.execute_reply": "2021-08-11T07:37:04.421801Z",
     "shell.execute_reply.started": "2021-06-21T09:33:27.621832Z"
    },
    "papermill": {
     "duration": 0.754463,
     "end_time": "2021-08-11T07:37:04.422437",
     "exception": false,
     "start_time": "2021-08-11T07:37:03.667974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a38614",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val_loss, test_val_acc = model.evaluate(X_validation, y_validation, verbose=0)\n",
    "print(\"Test Val Accuracy: \", test_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d6fd34d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T07:37:05.501678Z",
     "iopub.status.busy": "2021-08-11T07:37:05.500716Z",
     "iopub.status.idle": "2021-08-11T07:37:05.534204Z",
     "shell.execute_reply": "2021-08-11T07:37:05.533768Z"
    },
    "papermill": {
     "duration": 0.603561,
     "end_time": "2021-08-11T07:37:05.534325",
     "exception": false,
     "start_time": "2021-08-11T07:37:04.930764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('Speech-Emotion-Recognition-Model-DeepTalk-LSTM-Allsamples.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22c65f4",
   "metadata": {},
   "source": [
    "## Confusion Matrix and Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48c11ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "#model = keras.models.load_model('Models/Speech-Emotion-Recognition-Model-subjectdisjoint-133.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29a7d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.922531671421503, 0.15322581]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5450286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a961680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_predicted.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c7fb191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x936 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "plt.figure(figsize=(15,13))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(matrix, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('LSTM-Based Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['disgust','happy','sad','neutral','fear','angry']); ax.yaxis.set_ticklabels(['disgust','happy','sad','neutral','fear','angry']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2df3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1027.117369,
   "end_time": "2021-08-11T07:37:09.186557",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-11T07:20:02.069188",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
